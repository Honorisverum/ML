{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true) и ответы некоторого классификатора (колонка predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('csv_dataframes/classification.csv')\n",
    "true = data.true #true class\n",
    "pred = data.pred #prediction class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Заполните таблицу ошибок классификации. Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1. Ответ в данном вопросе — четыре числа через пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n"
     ]
    }
   ],
   "source": [
    "def class_err(true_class,pred_class):\n",
    "    if true_class == 1 and pred_class == 1:\n",
    "        return 'tp'\n",
    "    elif true_class == 0 and pred_class == 1:\n",
    "        return 'fp'\n",
    "    elif true_class == 1 and pred_class == 0:\n",
    "        return 'fn'\n",
    "    elif true_class == 0 and pred_class == 0:\n",
    "        return 'tn'\n",
    "    \n",
    "class_err_dict = dict(data.apply(lambda x: class_err(x[0],x[1]),axis=1).value_counts())\n",
    "\n",
    "tp = class_err_dict['tp']\n",
    "fp = class_err_dict['fp']\n",
    "fn = class_err_dict['fn']\n",
    "tn = class_err_dict['tn']\n",
    "print(tp,fp,fn,tn,sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Посчитайте основные метрики качества классификатора: Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score Precision (точность) — sklearn.metrics.precision_score Recall (полнота) — sklearn.metrics.recall_score F-мера — sklearn.metrics.f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.54\n",
      "precision: 0.56\n",
      "recall: 0.42\n",
      "f-score: 0.48\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.65      0.58        98\n",
      "          1       0.56      0.42      0.48       102\n",
      "\n",
      "avg / total       0.54      0.54      0.53       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', round(sklearn.metrics.accuracy_score(true, pred),2))\n",
    "print('precision:', round(sklearn.metrics.precision_score(true, pred),2))\n",
    "print('recall:', round(sklearn.metrics.recall_score(true, pred),2))\n",
    "print('f-score:', round(sklearn.metrics.f1_score(true, pred),2))\n",
    "print('\\n\\n\\n')\n",
    "print(sklearn.metrics.classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке: для логистической регрессии — вероятность положительного класса (колонка score_logreg), для SVM — отступ от разделяющей поверхности (колонка score_svm), для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn), для решающего дерева — доля положительных объектов в листе (колонка score_tree). Загрузите этот файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_data = pd.read_csv('csv_dataframes/scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'score_logreg'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "for x in another_data.columns[1:]:\n",
    "    scores[x] = sklearn.metrics.roc_auc_score(another_data.true, another_data[x])\n",
    "\n",
    "  \n",
    "def key_for_max_in_dict(now_dict):  \n",
    "     val = list(now_dict.values())\n",
    "     keys = list(now_dict.keys())\n",
    "     return keys[val.index(max(val))]\n",
    "\n",
    "key_for_max_in_dict(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ? Чтобы получить ответ на этот вопрос, найдите все точки precision-recall-кривой с помощью функции sklearn.metrics.precision_recall_curve. Она возвращает три массива: precision, recall, thresholds. В них записаны точность и полнота при определенных порогах, указанных в массиве thresholds. Найдите максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'score_tree'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "for x in another_data.columns[1:]:\n",
    "    curve = sklearn.metrics.precision_recall_curve(another_data.true, another_data[x])\n",
    "    df = pd.DataFrame({'precision': curve[0], 'recall': curve[1]})\n",
    "    scores[x] = df[df['recall'] >= 0.7]['precision'].max()\n",
    "    \n",
    "key_for_max_in_dict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
